{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PASTIS Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ellajewison/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv1D, UpSampling2D, MaxPooling2D, Dropout, Conv2DTranspose, concatenate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "POOL_SIZE = 3\n",
    "STRIDES = 2\n",
    "KERNEL_SIZE = 3\n",
    "UPSAMPLE_FACTOR = 2\n",
    "KERNEL_SIZE_1x1 = 1\n",
    "STRIDES_1x1 = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_conv_block(inputs, n_filters, dropout_prob):\n",
    "    \"\"\"\n",
    "    Single Convolutional downsampling block\n",
    "    inputs (batch_size,T,H,W,C)\n",
    "    \n",
    "    \"\"\"\n",
    "    conv = Conv2D(filters=n_filters, kernel_size=KERNEL_SIZE, strides=1, padding='same', kernel_initializer='he_normal')(inputs) # (batch_size,T,H,W,C)\n",
    "    if dropout_prob > 0: # if dropout, add Dropout layer\n",
    "        conv = Dropout(dropout_prob)(conv)\n",
    "    norm = tf.keras.layers.GroupNormalization(groups=4, axis=-1)(conv) # (batch_size,T,H,W,n_filters)\n",
    "    relu = tf.keras.layers.ReLU()(norm) # (batch_size,T,H,W,n_filters)\n",
    "\n",
    "    return relu\n",
    "\n",
    "def conv_block(inputs, n_filters, dropout_prob):\n",
    "    \"\"\"\n",
    "    Convolutional downsampling block\n",
    "    \n",
    "    Arguments:\n",
    "        inputs -- Input tensor (batch_size,T,H,W,C)\n",
    "        n_filters -- Number of filters for the convolutional layers\n",
    "        dropout_prob -- Dropout probability\n",
    "        max_pooling -- Use MaxPooling2D to reduce the spatial dimensions of the output volume\n",
    "    Returns: \n",
    "        next_layer, skip_connection --  Next layer and skip connection outputs\n",
    "    \"\"\"\n",
    "\n",
    "    relu1 = single_conv_block(inputs=inputs, n_filters=n_filters, dropout_prob=dropout_prob) # (batch_size,T,H,W,n_filters)\n",
    "    relu2 = single_conv_block(inputs=relu1, n_filters=n_filters, dropout_prob=dropout_prob) # (batch_size,T,H,W,n_filters)\n",
    "    output = tf.concat([relu1, relu2], axis=-1) # (batch_size,T,H,W, n_filters*2)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def conv_pool_block(inputs, n_filters, dropout_prob):\n",
    "    \"\"\"\n",
    "    inputs (batch_size,T,H,W,C)\n",
    "    \"\"\"\n",
    "    skip_connection = conv_block(inputs=inputs, n_filters=n_filters, dropout_prob=dropout_prob) # (batch_size,T,H,W,n_filters)\n",
    "    batch_size, T, H, W, n_filters_2 = skip_connection.shape\n",
    "    temp = tf.reshape(skip_connection, shape=(batch_size*T,  H, W, n_filters_2)) # (batch_size*T,H,W,n_filters_2)\n",
    "    output = MaxPooling2D(pool_size=POOL_SIZE, strides=STRIDES, padding='same')(temp) # (batch_size*T,(H-1)//2+1,(W-1)//2+1,n_filters_2)\n",
    "    batch_size_T, H2, W2, n_filters = output.shape\n",
    "    output_reshaped = tf.reshape(output, shape=(batch_size, T, H2, W2, n_filters)) \n",
    "\n",
    "    return output_reshaped, skip_connection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug\n",
    "batch_size, T, H, W, C = 2,4,8,8,6\n",
    "dropout_prob = 0.15\n",
    "input_shape = [batch_size, T, H, W, C]\n",
    "inputs = tf.random.normal(shape=input_shape)\n",
    "strides = 2\n",
    "conv_pool_block_outputshape_H = math.floor((H - 1) / strides) + 1\n",
    "n_filters = 32\n",
    "\n",
    "assert(single_conv_block(inputs, n_filters, dropout_prob).shape == [batch_size,T,H,W,n_filters])\n",
    "assert(conv_block(inputs, n_filters, dropout_prob).shape == [batch_size,T,H,W, n_filters*2])\n",
    "assert(conv_pool_block(inputs, n_filters, dropout_prob)[0].shape == [batch_size,T,conv_pool_block_outputshape_H,conv_pool_block_outputshape_H, n_filters*2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def single_upconv_block(input, n_filters):\n",
    "    \"\"\"\n",
    "    Convolution unit with Batch Normalization and Relu:\n",
    "\n",
    "    Arguments:\n",
    "        input -- Input tensor (batch_size,H,W,C)\n",
    "        n_filters -- number of filter for the convolutional layers\n",
    "\n",
    "    Returns: \n",
    "        conv -- Tensor output\n",
    "    \"\"\"\n",
    "    conv = Conv2D(n_filters,kernel_size=KERNEL_SIZE, padding=\"same\",kernel_initializer='he_normal')(input)\n",
    "    norm = tf.keras.layers.BatchNormalization()(conv) # (batch_size,H,W,n_filters)\n",
    "    relu = tf.keras.layers.ReLU()(norm) # (batch_size,H,W,n_filters)\n",
    "    return relu\n",
    "\n",
    "\n",
    "def conv_2D_transpose(input, n_filters):\n",
    "    return Conv2DTranspose(filters=n_filters, kernel_size=KERNEL_SIZE, strides=STRIDES,padding='same')(input) #(batch_size, H*STRIDES, W*STRIDES, n_filters)\n",
    "\n",
    "\n",
    "def up_conv_block(previous_layer, skip_connexion, n_filters):\n",
    "    \"\"\"\n",
    "    Convolutional upsampling block\n",
    "    \n",
    "    Arguments:\n",
    "        previous_layer -- Input tensor from previous layer (batch_size, H, W, C1)\n",
    "        skip_connexion -- Input tensor from previous skip layer (batch_size, H*STRIDES, W*STRIDES, C2)\n",
    "        n_filters -- Number of filters for the convolutional layers\n",
    "\n",
    "    Returns: \n",
    "        conv -- Tensor output (batch_size, H*STRIDES, W*STRIDES, n_filters*2)\n",
    "    \"\"\"\n",
    "    up = conv_2D_transpose(previous_layer, n_filters) # (batch_size, H*STRIDES, W*STRIDES, n_filters)\n",
    "    merge = tf.concat([up, skip_connexion], axis=-1) # (batch_size, H*STRIDES, W*STRIDES, n_filters + C2)\n",
    "                        \n",
    "    out1 = single_upconv_block(merge, n_filters=n_filters) # (batch_size, H*STRIDES, W*STRIDES, n_filters)\n",
    "    out2 = single_upconv_block(out1, n_filters=n_filters) # (batch_size, H*STRIDES, W*STRIDES, n_filters)\n",
    "    \n",
    "    output = tf.concat([out1, out2], axis=-1) # (batch_size, H*STRIDES, W*STRIDES, n_filters*2)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#debug\n",
    "batch_size, H, W, C1, C2 = 2,8,8,6,7\n",
    "input_shape = [batch_size, H, W, C1]\n",
    "inputs = tf.random.normal(shape=input_shape)\n",
    "skip_connexion_shape = [batch_size, H*STRIDES, W*STRIDES, C2]\n",
    "skip_connexion = tf.random.normal(shape=skip_connexion_shape)\n",
    "\n",
    "n_filters = 32\n",
    "\n",
    "assert(single_upconv_block(inputs, n_filters).shape == [batch_size, H, W, n_filters])\n",
    "previous_layer = conv_2D_transpose(inputs, n_filters)\n",
    "assert(previous_layer.shape == [batch_size, H*STRIDES, W*STRIDES, n_filters])\n",
    "assert(up_conv_block(inputs, skip_connexion, n_filters).shape == [batch_size, H*STRIDES, W*STRIDES, n_filters*2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_attention_masks(input, G, key_dim):\n",
    "    \"\"\"\n",
    "       Temporal Lightweight Attention Encoder \n",
    "    \n",
    "    Arguments:\n",
    "        input  -- Input tensor (batch, T, H, W, C)\n",
    "        G -- number of attention heads\n",
    "        key_dim -- Dimension of the key and query vectors.\n",
    "    Returns:\n",
    "        attention_mask -- attention mask (batch_size, G, T, H, W)\n",
    "    \"\"\"\n",
    "    Q_shape = [G, key_dim]\n",
    "    Q0 = tf.random.normal(shape=Q_shape)\n",
    "    Q = tf.Variable(initial_value=Q0, shape=Q_shape, trainable=True) # (G, key_dim)\n",
    "\n",
    "    C = input.shape[-1]\n",
    "    Wk_shape = (G, key_dim, C)\n",
    "    Wk0 = tf.random.normal(shape=Wk_shape)\n",
    "    Wk = tf.Variable(initial_value=Wk0, shape = Wk_shape, trainable=True) # (G, key_dim, C)\n",
    "    input_bcast = input[:,tf.newaxis,tf.newaxis,...]                   # (batch, 1, 1,       T, H, W,C)\n",
    "    Wk_bcast = Wk[tf.newaxis,:,:, tf.newaxis,tf.newaxis, tf.newaxis,:] # (1    , G, key_dim, 1, 1, 1,C)\n",
    "    K = tf.reduce_sum(input_bcast * Wk_bcast, axis=-1)                # (batch, G, key_dim, T, H, W)\n",
    "    Q_bcast = Q[tf.newaxis, :, :, tf.newaxis, tf.newaxis, tf.newaxis] # (1,     G, key_dim, 1, 1, 1)\n",
    "    QK = tf.reduce_sum(Q_bcast*K, axis=2) # (batch, G, T, H, W)\n",
    "\n",
    "    attention_mask = tf.nn.softmax(QK/tf.math.sqrt(float(key_dim)), axis=2) # (batch_size, G, T, H, W)\n",
    "    return attention_mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#debug\n",
    "batch_size, T, H, W, C = 2, 8, 64, 64, 6\n",
    "input_shape = [batch_size, T, H, W, C]\n",
    "input = tf.random.normal(shape=input_shape)\n",
    "G, key_dim = 9, 32\n",
    "\n",
    "attention_mask = compute_attention_masks(input, G, key_dim)\n",
    "assert(attention_mask.shape == [batch_size, G, T, H, W])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv_one_one(input, n_filters):\n",
    "    \"\"\"\n",
    "    Convolution 1x1 bloc\n",
    "    \n",
    "    Arguments:\n",
    "        input_size -- Input shape (batch_size, H, W, C)\n",
    "        n_filters -- Number of filters for the convolutional layers\n",
    "\n",
    "    Returns: \n",
    "        conv output Tensor (batch_size, H, W, n_filters)\n",
    "    \"\"\"\n",
    "\n",
    "    conv = Conv2D(filters=n_filters, kernel_size=KERNEL_SIZE_1x1, strides=STRIDES_1x1, padding='same', activation='relu')(input) # (batch_size, H, W, n_filters)\n",
    "    return conv \n",
    "\n",
    "def upsample_attention(attention_mask):\n",
    "    \"\"\"\"\n",
    "        Attention mask upsampling\n",
    "\n",
    "        Arguments:\n",
    "            attention_mask -- Input shape (batch_size, G, T, H, W)\n",
    "        Returns:\n",
    "            up_attention -- Output Tensor [batch_size, G, T, H*UPSAMPLE_FACTOR, W*UPSAMPLE_FACTOR]\n",
    "\n",
    "    \"\"\"\n",
    "    batch_size, G, T, H, W = attention_mask.shape\n",
    "    attention_mask_reshaped = tf.reshape(attention_mask, shape=[batch_size*G, T, H, W])\n",
    "    up_attention = UpSampling2D(size=UPSAMPLE_FACTOR, interpolation='bilinear', data_format='channels_first')(attention_mask_reshaped) # (batch_size*G, T, H*UPSAMPLE_FACTOR, W*UPSAMPLE_FACTOR)\n",
    "    up_attention = tf.reshape(up_attention, shape=[batch_size, G, T, H*UPSAMPLE_FACTOR, W*UPSAMPLE_FACTOR])\n",
    "    # so the upsampled dim are the last2\n",
    "    return up_attention\n",
    "\n",
    "def block_wise_temporal_ws(input, attention_mask):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        input -- (batch_size, T, H, W, C)\n",
    "        attention_mask -- (batch_size, G, T, H, W)\n",
    "    Returns :\n",
    "        weighted_sum (batch_size, H, W, C)\n",
    "    \n",
    "    \"\"\"\n",
    "    input_reshaped = tf.transpose(input, perm=[0,4,1,2,3]) # (batch_size, C, T, H, W)\n",
    "    batch_size, C, T, H, W = input_reshaped.shape\n",
    "    input_reshaped = tf.reshape(input_reshaped, shape = [batch_size, G, C//G, T, H, W])\n",
    "    attention_mask_bcast = attention_mask[:, :, tf.newaxis, ...]\n",
    "    weighted_sum = tf.math.reduce_sum(input_reshaped * attention_mask_bcast, axis=3) # (batch_size, G, C//G, H, W)\n",
    "    weighted_sum = tf.reshape(weighted_sum, shape=[batch_size, C, H, W])\n",
    "    weighted_sum = tf.transpose(weighted_sum, perm=[0,2,3,1]) # (batch_size, H, W, C)\n",
    "    return weighted_sum\n",
    "\n",
    "def temporal_ws_and_conv_one_one(input, attention_mask, n_filters):\n",
    "    ws = block_wise_temporal_ws(input, attention_mask)\n",
    "    return conv_one_one(ws, n_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug conv_one_one & upsample_attention\n",
    "batch_size, T, H, W = 2, 8, 64, 64\n",
    "G = 4\n",
    "attention_mask_shape = [batch_size, G, T, H, W]\n",
    "input = tf.random.normal(shape=attention_mask_shape)\n",
    "key_dim = 32\n",
    "C = 6\n",
    "n_filters = 4\n",
    "input_one_one = tf.random.normal(shape=[batch_size, H, W, C])\n",
    "\n",
    "assert(upsample_attention(input).shape == [batch_size, G, T, H*UPSAMPLE_FACTOR, W*UPSAMPLE_FACTOR])\n",
    "assert(conv_one_one(input_one_one,n_filters).shape == [batch_size, H, W, n_filters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#debug block_wise_temporal_ws\n",
    "batch_size, T, H, W = 2, 8, 64, 64\n",
    "C = 12\n",
    "G = 4\n",
    "input = tf.random.normal(shape=[batch_size, T, H, W, C]) # output from conv block\n",
    "attention_mask = tf.random.normal(shape=[batch_size, G, T, H, W]) \n",
    "\n",
    "assert(block_wise_temporal_ws(input,attention_mask).shape == [batch_size, H, W, C])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model(input, n_filters, G, dropout_prob, key_dim, L):\n",
    "    \"\"\"\n",
    "    Unet model model with LTAE temporal attention head\n",
    "    \n",
    "    Arguments:\n",
    "        inputs -- Input tensor (batch_size, T, H, W, C)\n",
    "        n_filters -- Number of filters for the convolutional layers\n",
    "        n_classes -- Number of output classes\n",
    "        G -- number of attention heads\n",
    "        key_dim -- dimension of encoding of the attention head\n",
    "        L  -- number of layer/levels in the UNET architecture\n",
    "        dropout_prob -- Dropout_prob probability\n",
    "\n",
    "    Returns: \n",
    "        outputs -- list of output tensor\n",
    "    \"\"\"\n",
    "\n",
    "    # encoder\n",
    "    skip_connections = []\n",
    "    input_conv = input \n",
    "    for _ in range(L-1):\n",
    "        conv, skip_connection = conv_pool_block(input_conv, n_filters, dropout_prob)\n",
    "        skip_connections.append(skip_connection)\n",
    "        input_conv = conv\n",
    "    skip_connection = conv_block(input_conv, n_filters, dropout_prob)\n",
    "    skip_connections.append(skip_connection)\n",
    "    assert(len(skip_connections) == L)\n",
    "\n",
    "    # decoder\n",
    "    attention_mask = compute_attention_masks(skip_connections[-1], G, key_dim)\n",
    "\n",
    "    # apply temporal attention mask and conv1x1\n",
    "    for i in range(L-1, -1, -1): #(L-1, L-2, ..., 1)\n",
    "        skip_connections[i] = temporal_ws_and_conv_one_one(skip_connections[i], attention_mask, n_filters)\n",
    "        if i > 0:\n",
    "            attention_mask = upsample_attention(attention_mask)\n",
    "\n",
    "    # decoder\n",
    "    outputs = [skip_connections[-1]]\n",
    "    previous_layer = skip_connections[-1]\n",
    "    for i in range(L-1, 0, -1): #(L-1, L-2, ..., 1)\n",
    "        previous_layer = up_conv_block(previous_layer, skip_connections[i-1], n_filters)\n",
    "        outputs.append(previous_layer)\n",
    "\n",
    "    return reversed(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug\n",
    "n_filters, G, dropout_prob, key_dim, L = 8, 2, 0.15, 32, 4\n",
    "batch_size,T,H,W,C = 2, 4, 64, 64, 32\n",
    "input_shape = (batch_size,T,H,W,C)\n",
    "input = tf.random.normal(shape=input_shape)\n",
    "\n",
    "outputs = unet_model(input, n_filters, G, dropout_prob, key_dim, L)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
